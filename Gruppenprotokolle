*11.04.2022 - 17.04.2022*

DONE:
- Finden der Gruppenzusammensetzung ✓
- Finden einer Kommunikationsstruktur - Telegram ✓
- Finden eines regelmäßigen Termins für Treffen - alle zwei Wochen Mo. od. Mi. um 10 ✓
- Aufsetzen eines Githubs? // Klären der Kommunikationswege für Date(i)n ✓
- Wie funktioniert das LIDO-XML? (Kate)

TO DO:
- Finden von Problemen der bestehenden Suchmaschine für die Sammlung Online https://sammlungonline.mkg-hamburg.de/de 
- Sammeln der Probleme auf dem Pad "Probleme.txt"
- Anfragen nach aktualisierten Datensätzen + eventuell bekannten Fehlern der Suchmaschine am MKG (Lea)
- Einschätzen der bisherigen SuMa nach Kriterien der Vorlesung
- Dinge von Maik Fröbe durchgehen

26.04.:
Ergebnisse der Fragen an Dozentin nach VL:
- pyterrier benutzen, daten da einspeisen und versuchen die ersten queries zu stellen
- überblick bekommen: welche retrieval modelle gibt es? welche sind für uns geeignet? Wie machen wir Indizierung unserer Daten?
- GUI nicht nötig, textausgabe reicht
- Einpflegen in IR-Datenbank optional, geht evt. über das Ziel des Projekts hinaus
- Literature Research sollten wir anfangen, aber kann im laufe des Projekts vervollst. werden.
  Dazu nur Überblick über bestehende literatur verschaffen, evt. ähnliche bestehende Tasks finden
- Query Expansion / Suchvervollständigung können wir auch schon bald am Anfang machen

19.05.:
# Überlegungen zu elasticsearch und elasticsearch-dsl:
## Womöglich elasticsearch-dsl nicht notwendig, können direkt mit elasticsearch arbeiten
Begründung:
es-dsl bietet die Möglichkeit eine Wrapper Klasse zu definieren, die alle Attribute eines Dokuments enthält.
Darauf kann man auch direkt den Stemmer festlegen, und Instanzen dieser Klasse dann zum Indexen benutzen. siehe dazu: 
https://elasticsearch-dsl.readthedocs.io/en/latest/#persistence-example siehe dazu:

Jedoch sind unsere Daten sehr tief verschachtelt und haben viele Attribute. (Im Gegensatz zum gezeigten Beispiel - hier werden 
Blog Einträge verwendet die nur title, timestamp, body, etc haben.)
In dieser Frage wird auf genau das Problem eingegangen:
https://stackoverflow.com/questions/58850693/how-to-index-large-json-response-in-elasticsearch-in-python-using-elasticsearc
Da wird dann empfohlen, einfach kein es-dsl zu verwenden, sondern elasticsearch

# Überlegungen zum Stemming / Lemmatisierung
ES supported nur Stemming, keine Lemmatisierung. Die Frage ist, ob uns das reicht, und wenn nein, ob es möglich ist, 
die Lemmatisierung vorab händisch zu machen.
Das könnte man vllt so angehen:
- textuelle attribute die description, tags, etc, die fürs Retrieval wichtig sind, mit nltk lemmatisieren
- dann ganz normal das indexing durchführen, ohne stemming
- suchanfragen ebenfalls lemmatisieren
